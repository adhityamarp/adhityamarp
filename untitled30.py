# -*- coding: utf-8 -*-
"""Untitled30.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TYtU5HZbEZnftyyFbzSgzlMDQXMILPAj
"""

!pip install transformers sentence-transformers PyPDF2 python-docx tensorflow

from transformers import BertTokenizer, TFBertModel
from sentence_transformers import SentenceTransformer, util
import tensorflow as tf
import PyPDF2
from docx import Document
import random

# Load BERT model and tokenizer
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model = TFBertModel.from_pretrained("bert-base-uncased")
st_model = SentenceTransformer("all-MiniLM-L6-v2")  # For distractors

def extract_text_from_pdf(file_path):
    """Extract text from a PDF."""
    with open(file_path, 'rb') as pdf_file:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            text += page.extract_text()
    return text

def extract_text_from_docx(file_path):
    """Extract text from a DOCX file."""
    doc = Document(file_path)
    text = ""
    for paragraph in doc.paragraphs:
        text += paragraph.text + "\n"
    return text

def encode_with_bert(text):
    """Encode text using BERT."""
    encoded_input = bert_tokenizer(text, return_tensors="tf", truncation=True, max_length=512, padding="max_length")
    output = bert_model(encoded_input)
    return output.last_hidden_state

def generate_question_bert(sentence):
    """Generate a question from a sentence using BERT embeddings."""
    # Use a simple heuristic to form questions
    if "is" in sentence or "are" in sentence:
        return f"What {sentence.split('is' if 'is' in sentence else 'are')[0].strip()}?"
    elif "can" in sentence:
        return f"What can {sentence.split('can')[0].strip()} do?"
    else:
        return f"What is the meaning of '{sentence.strip()}'?"

def generate_distractors_bert(correct_answer, context):
    """Generate distractors using Sentence Transformers."""
    correct_embedding = st_model.encode(correct_answer, convert_to_tensor=True)
    context_embedding = st_model.encode(context, convert_to_tensor=True)

    # Find words in the context with similar embeddings
    distractors = []
    for word in context.split():
        word_embedding = st_model.encode(word, convert_to_tensor=True)
        similarity = util.pytorch_cos_sim(correct_embedding, word_embedding).item()
        if 0.5 < similarity < 0.8:  # Ensure semantic closeness
            distractors.append(word)
    return list(set(distractors))[:3]  # Return top 3 unique distractors

import random

def generate_mcqs(text):
    """Generate MCQs with improved blank placement."""
    sentences = text.split('.')
    questions = []

    for sentence in sentences:
        if len(sentence.strip()) < 10:
            continue

        # --- Improved Blank Placement Logic ---
        words = sentence.split()
        blank_position = random.randint(1, len(words) - 2)  # Avoid first and last words

        # Create the question with blank
        question_words = words[:]  # Create a copy of words
        correct_answer = question_words[blank_position]
        question_words[blank_position] = "__________"
        question = " ".join(question_words)

        distractors = generate_distractors_bert(correct_answer, sentence)

        # --- End of Improved Logic ---

        if len(distractors) < 3:
            continue

        options = [correct_answer] + distractors
        random.shuffle(options)

        questions.append({
            "question": question,
            "correct_answer": correct_answer,
            "options": options
        })
    return questions

def display_questions_dynamic(questions, num_questions):
    """Display questions interactively for the user."""
    selected_questions = random.sample(questions, min(num_questions, len(questions)))
    score = 0

    for i, q in enumerate(selected_questions, 1):
        print(f"Q{i}: {q['question']}")
        for j, option in enumerate(q['options'], 1):
            print(f"   {j}. {option}")
        try:
            answer = int(input("Your answer (enter option number): "))
            if q['options'][answer - 1] == q['correct_answer']:
                score += 1
                print("Correct!")
            else:
                print(f"Incorrect. The correct answer is: {q['correct_answer']}")
        except (ValueError, IndexError):
            print("Invalid input! Moving to the next question.")
    return score, len(selected_questions)

if __name__ == "__main__":
    file_path = input("Enter the path to your PDF or DOCX file: ")

    # Extract text
    if file_path.endswith(".pdf"):
        text = extract_text_from_pdf(file_path)
    elif file_path.endswith(".docx"):
        text = extract_text_from_docx(file_path)
    else:
        print("Unsupported file type! Please provide a PDF or DOCX file.")
        exit()

    # Generate MCQs
    questions = generate_mcqs(text)
    print(f"{len(questions)} questions generated.")

    # User attempts
    num_questions = int(input("Enter the number of questions you want to attempt: "))
    score, total = display_questions_dynamic(questions, num_questions)
    print(f"You scored {score}/{total}.")

